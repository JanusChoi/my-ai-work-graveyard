import requests
import os,sys,time
from bs4 import BeautifulSoup
import json
import re
import pandas as pd
import datetime
from collections import defaultdict
import configparser
import pymongo
from tqdm import tqdm
import matplotlib.pyplot as plt
import logging

import openai
from langchain.document_loaders import UnstructuredFileLoader
from langchain.chains.summarize import load_summarize_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from langchain import OpenAI
from langchain.chat_models import AzureChatOpenAI
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)

logging.basicConfig(filename='./_data_workflow/basic_data_staging.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# è¿è¡Œç¯å¢ƒåˆå§‹åŒ–
os.environ["http_proxy"] = "http://127.0.0.1:1088"
os.environ["https_proxy"] = "http://127.0.0.1:1088"
os.environ["OPENAI_API_KEY"] = "your_key"

BASE_URL = "https://myapp.openai.azure.com/"
API_KEY = "your_key"
DEPLOYMENT_NAME = "gpt-35-turbo"

#################### é€šçŸ¥æ¨¡å—
def push_wecom(content):
    msg = '{""msgtype"":""markdown"",""markdown"":{""content"":' + content + '}}'
    msg = '{"msgtype":"markdown","markdown":{"content":"' + content + '"}}'
    os_command = 'curl \'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=your_key\' \
    -H \'Content-Type: application/json\' \
    -d \'' + msg + '\''
    os.system(os_command)
    time.sleep(0.2)

# æ¥å£æ•°æ®mapping
def extract_info(item):
    owner, repo = item['hl_name'].replace('</em>','').replace('<em>','').split('/')
    access_url = f"https://github.com/{owner}/{repo}"
    description = item['hl_trunc_description']
    is_organization = item['owned_by_organization']
    language = item['language']
    stars = item['followers']
    topics = item['topics']
    
    return {
        'owner': owner,
        'repo':repo,
        'access_url':access_url,
        'description': description,
        'is_organization': is_organization,
        'language': language,
        'stars': stars,
        'topics': topics
    }

# æ¥å£æ•°æ®mapping
def extract_info_api(item):
    try:
        owner = item['owner']['login']
        repo = item['name']
        access_url = item['html_url']
        description = item['description']
        is_organization = item.get('organization', {}).get('type', '') == 'Organization'
        language = item['language']
        stars = item['stargazers_count']
        topics = item['topics']
        created_at = item['created_at']
        updated_at = item['updated_at']
        size = item['size']
        has_wiki = item['has_wiki']
        forks_count = item['forks_count']
        open_issues_count = item['open_issues_count']
        if item.get('license', {}) is not None:
            license_name = item.get('license', {}).get('name', {})
        else:
            license_name = "no license"

        return {
            'owner': owner,
            'repo':repo,
            'access_url':access_url,
            'description': description,
            'is_organization': is_organization,
            'language': language,
            'stars': stars,
            'topics': topics,
            'created_at': created_at,
            'updated_at': updated_at,
            'size': size,
            'has_wiki': has_wiki,
            'forks_count': forks_count,
            'open_issues_count': open_issues_count,
            'license_name': license_name
        }
    except Exception as e:
        print(f"Error occurred while extracting info from item: {item}")
        raise e

# å¤„ç† mongo è¿æ¥
class mongo_connector:
    def __init__(self, server_profiles):
        self.mongo_host = ''
        self.mongo_database = ''
        self.mongo_client = ''
        self.start_time = datetime.datetime.now()
        self.end_time = datetime.datetime.now() + datetime.timedelta(minutes=40)
        
        self.server_profiles = server_profiles
    
    def get_config(self):
        """è¯»å–é…ç½®æ–‡ä»¶è·å–ç›¸å…³ä¿¡æ¯"""
        print("è¿æ¥ç¯å¢ƒï¼š{}".format(self.server_profiles))
        cf = configparser.ConfigParser()
        cf.read("/Users/januswing/code/awesome-gpt-dev/_data_workflow/config.ini")
        
        self.mongo_host = 'mongodb://{}:{}/'.format(cf.get(self.server_profiles, 'mongo_host'), cf.get(self.server_profiles, 'mongo_port'))
        self.mongo_database = cf.get(self.server_profiles, 'mongo_database')
        self.mongo_client = pymongo.MongoClient(self.mongo_host)[self.mongo_database]

def web_advsearch(base_url):
    project_data = []
    page = 1
    while True:
        print(f"æ­£åœ¨çˆ¬å–ç¬¬{page}é¡µ")
        url = base_url + str(page)

        headers = {
        'authority': 'github.com',
        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
        'cache-control': 'max-age=0',
        'cookie': 'your_cookies',
        'if-none-match': 'W/"866a4073e03db5ba881df79c53a090be"',
        'referer': 'https://github.com/search/advanced',
        'sec-ch-ua': '"Chromium";v="112", "Microsoft Edge";v="112", "Not:A-Brand";v="99"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"macOS"',
        'sec-fetch-dest': 'document',
        'sec-fetch-mode': 'navigate',
        'sec-fetch-site': 'same-origin',
        'sec-fetch-user': '?1',
        'upgrade-insecure-requests': '1',
        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36 Edg/112.0.1722.68'
        }

        response = requests.get(url, headers=headers)
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            embedded_data = soup.find('script', {'type': 'application/json', 'data-target': 'react-app.embeddedData'})
            data = json.loads(embedded_data.string)
            search_results = data['payload']['results']
            items = search_results
            if items == []:
                break
            for item in items:
                project_info = extract_info(item)
                project_data.append(project_info)
        else:
            print(f"Failed to fetch data: {response.status_code}, {response.reason}, {response.url}")
        time.sleep(1)
        page += 1
    return project_data

# æ„é€ æŸ¥è¯¢url
def construct_url(created, stars, label):
    return "https://github.com/search?q=GPT+OR+LLM+OR+Transformer+OR+\"large+language+model\"+stars%3A>1000&type=repositories&ref=advsearch&s=stars&o=desc&p="

# æå–é¡¹ç›®æ‰€æœ‰commitsæ•°æ®ï¼ŒæŒ‰å¤©æ±‡æ€»
def get_repo_commits(owner, repo):
    commits_by_date = defaultdict(int)
    base_url = f"https://api.github.com/repos/{owner}/{repo}/commits"
    headers = {
        "Accept": "application/vnd.github+json",
        "Authorization": "token your_github_token"
    }
    page = 1

    while True:
        url = f"{base_url}?page={page}"
        response = requests.get(url, headers=headers)

        if response.status_code != 200:
            print(f"Failed to fetch data: {response.status_code}, {response.reason}, {response.url}")
            break

        data = json.loads(response.text)
        if not data:  # If the response data is empty, we've reached the end of the commits list
            break

        for commit in data:
            date_str = commit['commit']['author']['date']
            date = datetime.datetime.strptime(date_str, '%Y-%m-%dT%H:%M:%SZ').date()
            commits_by_date[date] += 1

        page += 1
    print(f"Found {len(commits_by_date)} commit dates for {owner}/{repo}.")

    return dict(commits_by_date)

# è¾“å‡ºé¡¹ç›®urlï¼Œè¿”å›ReadMeæ€»ç»“åŠä¸‰ä¸ªé™å®šèŒƒå›´å†…çš„æ ‡ç­¾
"""
{
    "repo_summary": "{summary_text}",
    "repo_tag1": "",
    "repo_tag2": "",
    "repo_tag3": ""
}
"""
def get_repo_summary(access_url):
    print(f"getting summary from repo:{access_url}")
    url = access_url.replace("github.com", "raw.githubusercontent.com").replace("/tree/", "/") + "/master/README.md"
    try:
        readme_txt = requests.get(url).text
    except:
        logging.ERROR(f"Error fetching or processing {url}, exeption: {sys.exc_info()[0]}")

    with open("/Users/januswing/data/tmp_readme.txt", "w") as f:
        f.write(readme_txt)
    f.close()
    # åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size = 2000,  # ä¸€ä¸ªchunkçš„å¤§å°
        chunk_overlap = 200 # åŒ…å«å¤šå°‘ä¸Šä¸€ä¸ªchunkç»“å°¾çš„å†…å®¹
    )

    # åˆ‡åˆ†æ–‡æœ¬
    with open("/Users/januswing/data/tmp_readme.txt") as f:
        readme_file = f.read()
    readme_texts = text_splitter.split_text(readme_file)

    readme_docs = [Document(page_content=t) for t in readme_texts]

    chat = ChatOpenAI(model_name="gpt-3.5-turbo", max_tokens=2048)

    # åˆ›å»ºæ€»ç»“é“¾
    chain = load_summarize_chain(chat, chain_type="map_reduce", verbose=False)

    # æ‰§è¡Œæ€»ç»“é“¾
    print(f"starting chain with readme_docs total size={len(readme_docs)}")
    if len(readme_docs) > 8:
        readme_docs = readme_docs[:8]
    summarization_eng = chain.run(readme_docs)

    chat_template="""
    You are a helpful assistant.
    """
    chat_prompt="è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¿»è¯‘ä¸ºä¸­æ–‡{}".format(summarization_eng)

    # chat = ChatOpenAI(model_name="gpt-3.5-turbo", max_tokens=2048)

    messages = [
        SystemMessage(content=chat_template),
        HumanMessage(content=chat_prompt)
    ]
    print("summary done")
    summarization_chn = chat(messages).content
    
    project_tags = """
    autonomous	GPTè‡ªåŠ¨åŒ–
    algorithm	ç®—æ³•å®ç°
    selfhostLLM	ä½æˆæœ¬è‡ªæ‰˜ç®¡LLM
    academic	å­¦æœ¯å·¥ä½œè¾…åŠ©
    Image recognition	å›¾åƒè¯†åˆ«ç›¸å…³
    mirror	é•œåƒæˆ–å¤‡ä»½ç«™
    text-to-speech	è¯­éŸ³è¯†åˆ«ç›¸å…³
    plugin	æ’ä»¶
    code	ä»£ç å·¥å…·
    awesome-list	æ¸…å•ï¼Œå­¦ä¹ èµ„æ–™
    fine-tune	æ¨¡å‹å¾®è°ƒ
    game	æ¸¸æˆç›¸å…³
    prompt	æç¤ºè¯å·¥ç¨‹
    data	æ•°æ®å¤„ç†
    industry	è¡Œä¸šç‰¹å®šåº”ç”¨
    IMbot	åµŒå…¥å·¥å…·ä¸­çš„æœºå™¨äºº
    Education	æ•™è‚²ç›¸å…³åº”ç”¨
    NA	ä¸ç›¸å…³
    """

    chat_prompt="""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±githubç©å®¶ï¼ŒåŒæ—¶ä¹Ÿæ˜¯ä¸€ä½å…¨æ ˆå·¥ç¨‹å¸ˆã€‚è¯·æ ¹æ®è¿™ä¸€å¥—å¼€æºé¡¹ç›®åˆ†ç±»{}ï¼Œåˆ¤æ–­ä»¥ä¸‹é¡¹ç›®ReadMeå†…å®¹ï¼Œç»™å‡º5ä¸ªåˆç†çš„æ ‡ç­¾ï¼Œå¹¶æ ‡è®°æ ‡ç­¾å¯èƒ½æ€§çš„æ¦‚ç‡(ä¸¤ä½å°æ•°)ï¼Œè¯·ç”¨jsonæ ¼å¼è¾“å‡ºä½ çš„ç»“æœï¼Œåªè¾“å‡ºjsonæ•°æ®ç»“æœå³å¯ï¼š{}""".format(project_tags, summarization_chn)
    # chat = ChatOpenAI(model_name="gpt-3.5-turbo", max_tokens=2048)
    messages = [
        SystemMessage(content=chat_template),
        HumanMessage(content=chat_prompt)
    ]
    tags_json = chat(messages)
    # è·å–åˆ†å€¼æœ€é«˜çš„ä¸‰ä¸ªtag
    try:
        tags_json = json.loads(tags_json.content)
        top_tags = sorted(tags_json, key=tags_json.get, reverse=True)[:3]
        repo_summary = {
            "repo_summary": summarization_chn,
            "repo_tag1": top_tags[0],
            "repo_tag2": top_tags[1],
            "repo_tag3": top_tags[2]
        }
        print("repo tagged")
    except Exception as e:
        print(f"getting top_tags failed, json format may be invalid:{e}")
        repo_summary = {
            "repo_summary": summarization_chn,
            "repo_tag1": "json invalid",
            "repo_tag2": "json invalid",
            "repo_tag3": "json invalid"
        }
    return repo_summary

# ç»Ÿä¸€é€šè¿‡GitHub APIè·å–é¡¹ç›®ä¿¡æ¯
def get_repo_info(owner, repo):
    url = f"https://api.github.com/repos/{owner}/{repo}"
    headers = {'Authorization': 'Bearer your_token'}
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        p = json.loads(response.text)
        p = extract_info_api(p)
        p['sync_time'] = datetime.datetime.now().strftime("%Y-%m-%d")
        return p
    else:
        # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„é¡¹ç›®ï¼Œåˆ™æŠ¥é”™ï¼Œè¯´æ˜è¯¥é¡¹ç›®çš„æ³¨å†Œä¿¡æ¯åœ¨GitHubä¸Šå·²è¢«æ›´æ”¹
        return 999

if __name__ == '__main__':
    logging.info("start to sync github project data...")

    # get input parameters
    env = sys.argv[1] # ç¯å¢ƒ dev/uat/prd
    # è·å–è¾“å…¥çš„github url
    if len(sys.argv) > 2:
        new_url = sys.argv[2]
        logging.info('adding repo manually: new_url: %s', new_url)
    else:
        new_url = None

    sync_time = datetime.datetime.now().strftime("%Y-%m-%d_%H|%M|%S")
    start_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    mongo_conn = mongo_connector(env)
    mongo_conn.get_config()
    mg_stage = mongo_conn.mongo_client
    tb_dim_github_project = mg_stage['dim_github_project']
    tb_his_github_project = mg_stage['his_github_project']
    tb_fact_github_project = mg_stage['fact_github_project']

    if new_url == None:
        logging.info("getting all related project data and update existing")
        # è·å–é¡¹ç›®ä¿¡æ¯
        created = '2023-03-01'
        stars = '%3A%3E1000'
        label = 'GPT'
        url = construct_url(created, stars, label)
        all_related_projects = web_advsearch(url)
        push_content = []
        # å°† all_related_projects è½¬æ¢ä¸ºå­—å…¸
        related_projects_dict = {(p['owner'], p['repo']): p for p in all_related_projects}
        # æ›´æ–°æ‰€æœ‰ç°å­˜é¡¹ç›®ä¿¡æ¯
        count = 0
        for project in tqdm(tb_dim_github_project.find()):
        # for project in tqdm(tb_dim_github_project.find({"summary": {"$exists": False}})):
            # if count < 580:
            #     count += 1
            #     continue
            owner = project['owner']
            repo = project['repo']
            current_stars = project['stars']
            p = get_repo_info(owner, repo)
            if p != 999:
                latest_stars = p['stars']
                if 'summary' not in project:
                    tmp_data = get_repo_summary(f"https://github.com/{owner}/{repo}")
                    p['summary'] = tmp_data['repo_summary']
                    p['tag1'] = tmp_data['repo_tag1']
                    p['tag2'] = tmp_data['repo_tag2']
                    p['tag3'] = tmp_data['repo_tag3']
                else:
                    # print(f"skipping project with column summary:{owner}/{repo}")
                    pass
                if latest_stars - current_stars > 200:
                    logging.info(f"Growing Project over 200 stars today: https://github.com/{owner}/{repo}")
                    description = p['description']
                    push_content.append(f"âœ…Growing Project over 200 stars today: [{repo}](https://github.com/{owner}/{repo})\nğŸŒŸ{latest_stars}\nhttps://github.com/{owner}/{repo}\n{description}")
                p['sync_time'] = datetime.datetime.now().strftime("%Y-%m-%d")
                tb_dim_github_project.update_one({'owner':owner, 'repo':repo}, {'$set':p})
                tb_his_github_project.insert_one(p)
            else:
                # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„é¡¹ç›®ï¼Œåˆ™æŠ¥é”™ï¼Œè¯´æ˜è¯¥é¡¹ç›®çš„æ³¨å†Œä¿¡æ¯åœ¨GitHubä¸Šå·²è¢«æ›´æ”¹
                logging.error("Project Not exist on github anymore Owner=%s, Repo=%s", owner, repo)
                continue
            
        # æ¯äº”æ¡ä¿¡æ¯æ•´åˆæ¨é€ï¼Œä¸æ»¡äº”æ¡åˆ™ç›´æ¥æ¨é€
        for i, push in enumerate(push_content):
            if i % 5 == 0:
                ready_to_push = ""
            ready_to_push += ''.join(push) + '\n'
            if (i + 1) % 5 == 0 or i == len(push_content) - 1:
                push_wecom(ready_to_push)
        
        # å°†æ–°æ•°æ®æ’å…¥åˆ°dim_github_projectè¡¨ä¸­
        for project in all_related_projects:
            owner = project['owner']
            repo = project['repo']
            stars = project['stars']
            description = project['description']
            # åˆ¤æ–­æ˜¯å¦å·²ç»å­˜åœ¨äºdim_github_projectè¡¨ä¸­
            if tb_dim_github_project.find_one({'owner': owner, 'repo': repo}):
                continue
            else:
                # ç»Ÿä¸€é€šè¿‡GitHub APIè·å–é¡¹ç›®ä¿¡æ¯
                url = f"https://api.github.com/repos/{owner}/{repo}"
                headers = {'Authorization': 'Bearer your_token'}
                response = requests.get(url, headers=headers)
                if response.status_code == 200:
                    p = json.loads(response.text)
                    p = extract_info_api(p)
                    latest_stars = p['stars']
                    if 'summary' not in project:
                        tmp_data = get_repo_summary(f"https://github.com/{owner}/{repo}")
                        p['summary'] = tmp_data['repo_summary']
                        p['tag1'] = tmp_data['repo_tag1']
                        p['tag2'] = tmp_data['repo_tag2']
                        p['tag3'] = tmp_data['repo_tag3']
                    p['sync_time'] = datetime.datetime.now().strftime("%Y-%m-%d")
                    # æ’å…¥dim_github_projectè¡¨
                    tb_dim_github_project.insert_one(p)
                    # æ’å…¥his_github_projectè¡¨
                    tb_his_github_project.insert_one(p)
                logging.info(f"New Project inserted: https://github.com/{owner}/{repo}")
                push_wecom(f"New Project inserted: [{repo}](https://github.com/{owner}/{repo})\nğŸŒŸ{stars}\nhttps://github.com/{owner}/{repo}\n{description}")

        # è·å–å‰50ä¸ªæ˜Ÿçº§é¡¹ç›®
        top_projects = list(tb_dim_github_project.find().sort([('stars', pymongo.DESCENDING)]).limit(50))

        # ç”Ÿæˆå›¾è¡¨
        x = [project['repo'] for project in top_projects]
        y = [project['stars'] for project in top_projects]
        plt.figure(figsize=(24, 12))
        plt.bar(x, y)
        plt.xticks(rotation=45, ha='right') # å°†æ¨ªè½´æ–‡å­—å€¾æ–œå¹¶ç«–å‘æ’åˆ—
        # è°ƒæ•´æ¨ªè½´æ–‡å­—çš„é¢œè‰²
        for i, tick in enumerate(plt.gca().get_xticklabels()):
            if i % 2 == 0:
                tick.set_color('blue')
            else:
                tick.set_color('red')
        plt.xlabel('Project')
        plt.ylabel('Stars')
        plt.title('Top 50 Stars Projects')
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨ä¸ºPNGæ ¼å¼ï¼Œå¹¶åœ¨æ–‡ä»¶åä¸­æ·»åŠ æ—¶é—´æˆ³
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        filename = f'top_stars_projects_{timestamp}.png'

        # åœ¨å›¾ç‰‡çš„å³ä¸Šè§’æ·»åŠ æ—¶é—´æˆ³
        plt.text(0.95, 0.95, timestamp, transform=plt.gca().transAxes, ha='right', va='top')

        plt.savefig(filename)
    else:
        # è§£ægithub urlï¼Œè·å–ownerå’Œrepo
        owner, repo = new_url.split('/')[-2:]

        # åˆ¤æ–­è¯¥é¡¹ç›®æ˜¯å¦å·²ç»å­˜åœ¨äºè¡¨ä¸­
        if tb_dim_github_project.find_one({'owner': owner, 'repo': repo}):
            print("Project already exists in the table.")
        else:
            # å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™é€šè¿‡GitHub APIè·å–é¡¹ç›®ä¿¡æ¯
            # ç»Ÿä¸€é€šè¿‡GitHub APIè·å–é¡¹ç›®ä¿¡æ¯
            url = f"https://api.github.com/repos/{owner}/{repo}"
            headers = {'Authorization': 'Bearer your_token'}
            response = requests.get(url, headers=headers)
            if response.status_code == 200:
                p = json.loads(response.text)
                p = extract_info_api(p)
                latest_stars = p['stars']
                tmp_data = get_repo_summary(f"https://github.com/{owner}/{repo}")
                p['summary'] = tmp_data['repo_summary']
                p['tag1'] = tmp_data['repo_tag1']
                p['tag2'] = tmp_data['repo_tag2']
                p['tag3'] = tmp_data['repo_tag3']
                p['sync_time'] = datetime.datetime.now().strftime("%Y-%m-%d")
                # æ’å…¥dim_github_projectè¡¨
                tb_dim_github_project.insert_one(p)
                # æ’å…¥his_github_projectè¡¨
                tb_his_github_project.insert_one(p)
                logging.info(f"New Project inserted: https://github.com/{owner}/{repo}")
            else:
                # å¦‚æœæ‰¾ä¸åˆ°å¯¹åº”çš„é¡¹ç›®ï¼Œåˆ™æŠ¥é”™ï¼Œè¯´æ˜è¯¥é¡¹ç›®çš„æ³¨å†Œä¿¡æ¯åœ¨GitHubä¸Šå·²è¢«æ›´æ”¹
                logging.error(f"Project does not exist on GitHub anymore: Owner={owner}, Repo={repo}")
    logging.info("Task finished")
    